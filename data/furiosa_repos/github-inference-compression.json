{
  "name": "inference-compression",
  "url": "https://github.com/furiosa-ai/inference-compression",
  "visibility": "public",
  "readme": {
    "title": "MLPerf™ Inference Benchmark Suite",
    "sections": [
      {
        "heading": "MLPerf™ Inference Benchmark Suite",
        "text": "MLPerf Inference is a benchmark suite for measuring how fast systems can run models in a variety of deployment scenarios.\nPlease see the\nMLPerf Inference benchmark paper\nfor a detailed description of the benchmarks along with the motivation and guiding principles behind the benchmark suite. If you use any part of this benchmark (e.g., reference implementations, submissions, etc.), please cite the following:\n@misc{reddi2019mlperf,\n    title={MLPerf Inference Benchmark},\n    author={Vijay Janapa Reddi and Christine Cheng and David Kanter and Peter Mattson and Guenther Schmuelling and Carole-Jean Wu and Brian Anderson and Maximilien Breughe and Mark Charlebois and William Chou and Ramesh Chukka and Cody Coleman and Sam Davis and Pan Deng and Greg Diamos and Jared Duke and Dave Fick and J. Scott Gardner and Itay Hubara and Sachin Idgunji and Thomas B. Jablin and Jeff Jiao and Tom St. John and Pankaj Kanwar and David Lee and Jeffery Liao and Anton Lokhmotov and Francisco Massa and Peng Meng and Paulius Micikevicius and Colin Osborne and Gennady Pekhimenko and Arun Tejusve Raghunath Rajan and Dilip Sequeira and Ashish Sirasao and Fei Sun and Hanlin Tang and Michael Thomson and Frank Wei and Ephrem Wu and Lingjie Xu and Koichi Yamada and Bing Yu and George Yuan and Aaron Zhong and Peizhao Zhang and Yuchen Zhou},\n    year={2019},\n    eprint={1911.02549},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG}\n}",
        "children": [
          {
            "heading": "MLPerf Inference v4.0 (submission deadline February 23, 2024)",
            "text": "Code freeze coming soon...",
            "children": []
          },
          {
            "heading": "MLPerf Inference v3.1 (submission August 18, 2023)",
            "text": "Please use\nv3.1 tag\n(\ngit checkout v3.1\n) if you would like to reproduce the v3.1 results.\nFor reproducing power submissions please use the\nmaster\nbranch of the\nMLCommons power-dev\nrepository and checkout to\ne9e16b1299ef61a2a5d8b9abf5d759309293c440\n.\nYou can see the individual README files in the benchmark task folders for more details regarding the benchmarks. For reproducing the submitted results please see the README files under the respective submitter folders in the\ninference v3.1 results repository\n.\nmodel\nreference app\nframework\ndataset\ncategory\nresnet50-v1.5\nvision/classification_and_detection\ntensorflow, onnx, tvm, ncnn\nimagenet2012\nedge,datacenter\nretinanet 800x800\nvision/classification_and_detection\npytorch, onnx\nopenimages resized to 800x800\nedge,datacenter\nbert\nlanguage/bert\ntensorflow, pytorch, onnx\nsquad-1.1\nedge,datacenter\ndlrm-v2\nrecommendation/dlrm_v2\npytorch\nMultihot Criteo Terabyte\ndatacenter\n3d-unet\nvision/medical_imaging/3d-unet-kits19\npytorch, tensorflow, onnx\nKiTS19\nedge,datacenter\nrnnt\nspeech_recognition/rnnt\npytorch\nOpenSLR LibriSpeech Corpus\nedge,datacenter\ngpt-j\nlanguage/gpt-j\npytorch\nCNN-Daily Mail\nedge,datacenter",
            "children": []
          },
          {
            "heading": "MLPerf Inference v3.0 (submission 03/03/2023)",
            "text": "Please use the v3.0 tag (\ngit checkout v3.0\n) if you would like to reproduce v3.0 results.\nYou can see the individual Readme files in the reference app for more details.\nmodel\nreference app\nframework\ndataset\ncategory\nresnet50-v1.5\nvision/classification_and_detection\ntensorflow, onnx, tvm\nimagenet2012\nedge,datacenter\nretinanet 800x800\nvision/classification_and_detection\npytorch, onnx\nopenimages resized to 800x800\nedge,datacenter\nbert\nlanguage/bert\ntensorflow, pytorch, onnx\nsquad-1.1\nedge,datacenter\ndlrm\nrecommendation/dlrm\npytorch, tensorflow\nCriteo Terabyte\ndatacenter\n3d-unet\nvision/medical_imaging/3d-unet-kits19\npytorch, tensorflow, onnx\nKiTS19\nedge,datacenter\nrnnt\nspeech_recognition/rnnt\npytorch\nOpenSLR LibriSpeech Corpus\nedge,datacenter",
            "children": []
          },
          {
            "heading": "MLPerf Inference v2.1 (submission 08/05/2022)",
            "text": "Use the r2.1 branch (\ngit checkout r2.1\n) if you want to submit or reproduce v2.1 results.\nSee the individual Readme files in the reference app for details.\nmodel\nreference app\nframework\ndataset\ncategory\nresnet50-v1.5\nvision/classification_and_detection\ntensorflow, onnx\nimagenet2012\nedge,datacenter\nretinanet 800x800\nvision/classification_and_detection\npytorch, onnx\nopenimages resized to 800x800\nedge,datacenter\nbert\nlanguage/bert\ntensorflow, pytorch, onnx\nsquad-1.1\nedge,datacenter\ndlrm\nrecommendation/dlrm\npytorch, tensorflow\nCriteo Terabyte\ndatacenter\n3d-unet\nvision/medical_imaging/3d-unet-kits19\npytorch, tensorflow, onnx\nKiTS19\nedge,datacenter\nrnnt\nspeech_recognition/rnnt\npytorch\nOpenSLR LibriSpeech Corpus\nedge,datacenter",
            "children": []
          },
          {
            "heading": "MLPerf Inference v2.0 (submission 02/25/2022)",
            "text": "Use the r2.0 branch (\ngit checkout r2.0\n) if you want to submit or reproduce v2.0 results.\nSee the individual Readme files in the reference app for details.\nmodel\nreference app\nframework\ndataset\ncategory\nresnet50-v1.5\nvision/classification_and_detection\ntensorflow, onnx\nimagenet2012\nedge,datacenter\nssd-mobilenet 300x300\nvision/classification_and_detection\ntensorflow, pytorch, onnx\ncoco resized to 300x300\nedge\nssd-resnet34 1200x1200\nvision/classification_and_detection\ntensorflow, pytorch, onnx\ncoco resized to 1200x1200\nedge,datacenter\nbert\nlanguage/bert\ntensorflow, pytorch, onnx\nsquad-1.1\nedge,datacenter\ndlrm\nrecommendation/dlrm\npytorch, tensorflow\nCriteo Terabyte\ndatacenter\n3d-unet\nvision/medical_imaging/3d-unet-kits19\npytorch, tensorflow, onnx\nKiTS19\nedge,datacenter\nrnnt\nspeech_recognition/rnnt\npytorch\nOpenSLR LibriSpeech Corpus\nedge,datacenter",
            "children": []
          },
          {
            "heading": "MLPerf Inference v1.1 (submission 08/13/2021)",
            "text": "Use the r1.1 branch (\ngit checkout r1.1\n) if you want to submit or reproduce v1.1 results.\nSee the individual Readme files in the reference app for details.\nmodel\nreference app\nframework\ndataset\ncategory\nresnet50-v1.5\nvision/classification_and_detection\ntensorflow, onnx\nimagenet2012\nedge,datacenter\nssd-mobilenet 300x300\nvision/classification_and_detection\ntensorflow, pytorch, onnx\ncoco resized to 300x300\nedge\nssd-resnet34 1200x1200\nvision/classification_and_detection\ntensorflow, pytorch, onnx\ncoco resized to 1200x1200\nedge,datacenter\nbert\nlanguage/bert\ntensorflow, pytorch, onnx\nsquad-1.1\nedge,datacenter\ndlrm\nrecommendation/dlrm\npytorch, tensorflow\nCriteo Terabyte\ndatacenter\n3d-unet\nvision/medical_imaging/3d-unet\npytorch, tensorflow(?), onnx(?)\nBraTS 2019\nedge,datacenter\nrnnt\nspeech_recognition/rnnt\npytorch\nOpenSLR LibriSpeech Corpus\nedge,datacenter",
            "children": []
          },
          {
            "heading": "MLPerf Inference v1.0 (submission 03/19/2021)",
            "text": "Use the r1.0 branch (\ngit checkout r1.0\n) if you want to submit or reproduce v1.0 results.\nSee the individual Readme files in the reference app for details.\nmodel\nreference app\nframework\ndataset\ncategory\nresnet50-v1.5\nvision/classification_and_detection\ntensorflow, onnx\nimagenet2012\nedge,datacenter\nssd-mobilenet 300x300\nvision/classification_and_detection\ntensorflow, pytorch, onnx\ncoco resized to 300x300\nedge\nssd-resnet34 1200x1200\nvision/classification_and_detection\ntensorflow, pytorch, onnx\ncoco resized to 1200x1200\nedge,datacenter\nbert\nlanguage/bert\ntensorflow, pytorch, onnx\nsquad-1.1\nedge,datacenter\ndlrm\nrecommendation/dlrm\npytorch, tensorflow(?)\nCriteo Terabyte\ndatacenter\n3d-unet\nvision/medical_imaging/3d-unet\npytorch, tensorflow(?), onnx(?)\nBraTS 2019\nedge,datacenter\nrnnt\nspeech_recognition/rnnt\npytorch\nOpenSLR LibriSpeech Corpus\nedge,datacenter",
            "children": []
          },
          {
            "heading": "MLPerf Inference v0.7 (submission 9/18/2020)",
            "text": "Use the r0.7 branch (\ngit checkout r0.7\n) if you want to submit or reproduce v0.7 results.\nSee the individual Readme files in the reference app for details.\nmodel\nreference app\nframework\ndataset\nresnet50-v1.5\nvision/classification_and_detection\ntensorflow, pytorch, onnx\nimagenet2012\nssd-mobilenet 300x300\nvision/classification_and_detection\ntensorflow, pytorch, onnx\ncoco resized to 300x300\nssd-resnet34 1200x1200\nvision/classification_and_detection\ntensorflow, pytorch, onnx\ncoco resized to 1200x1200\nbert\nlanguage/bert\ntensorflow, pytorch, onnx\nsquad-1.1\ndlrm\nrecommendation/dlrm\npytorch, tensorflow(?), onnx(?)\nCriteo Terabyte\n3d-unet\nvision/medical_imaging/3d-unet\npytorch, tensorflow(?), onnx(?)\nBraTS 2019\nrnnt\nspeech_recognition/rnnt\npytorch\nOpenSLR LibriSpeech Corpus",
            "children": []
          },
          {
            "heading": "MLPerf Inference v0.5",
            "text": "Use the r0.5 branch (\ngit checkout r0.5\n) if you want to reproduce v0.5 results.\nSee the individual Readme files in the reference app for details.\nmodel\nreference app\nframework\ndataset\nresnet50-v1.5\nv0.5/classification_and_detection\ntensorflow, pytorch, onnx\nimagenet2012\nmobilenet-v1\nv0.5/classification_and_detection\ntensorflow, pytorch, onnx\nimagenet2012\nssd-mobilenet 300x300\nv0.5/classification_and_detection\ntensorflow, pytorch, onnx\ncoco resized to 300x300\nssd-resnet34 1200x1200\nv0.5/classification_and_detection\ntensorflow, pytorch, onnx\ncoco resized to 1200x1200\ngnmt\nv0.5/translation/gnmt/\ntensorflow, pytorch\nSee Readme",
            "children": []
          }
        ]
      }
    ]
  },
  "metadata": {
    "description": "Reference implementations of MLPerf™ inference benchmarks",
    "license": null,
    "stars": 1,
    "forks": 0,
    "topics": [],
    "last_updated": "2024-07-05T14:38:58Z"
  }
}