{
  "name": "uncage",
  "url": "https://github.com/furiosa-ai/uncage",
  "visibility": "public",
  "readme": {
    "title": "UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation",
    "sections": [
      {
        "heading": "UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation",
        "text": "Paper Link\n:\narXiv",
        "children": [
          {
            "heading": "Abstract",
            "text": "Text-to-image (T2I) generation has been actively studied using Diffusion Models and Autoregressive Models. Recently, Masked Generative Transformers have gained attention as an alternative to Autoregressive Models to overcome the inherent limitations of causal attention and autoregressive decoding through bidirectional attention and parallel decoding, enabling efficient and high-quality image generation. However, compositional T2I generation remains challenging, as even state-of-the-art Diffusion Models often fail to accurately bind attributes and achieve proper text-image alignment. While Diffusion Models have been extensively studied for this issue, Masked Generative Transformers exhibit similar limitations but have not been explored in this context. To address this, we propose\nUnmasking with Contrastive Attention Guidance (UNCAGE)\n, a novel training-free method that improves compositional fidelity by leveraging attention maps to prioritize the unmasking of tokens that clearly represent individual objects. UNCAGE consistently improves performance in both quantitative and qualitative evaluations across multiple benchmarks and metrics, with negligible inference overhead.",
            "children": []
          },
          {
            "heading": "ðŸš§ Code Release Coming Soon",
            "text": "Thank you for your interest in our work!\nWe are actively working on preparing the codebase for public release. The code, along with documentation and example usage, will be made available here once it is ready.\nStay tuned!\nFor questions or collaboration inquiries, please contact us or open an issue.",
            "children": []
          },
          {
            "heading": "ðŸ“– Citation",
            "text": "If you find this useful, please cite:\n@article\n{\nkang2025uncage\n,\ntitle\n=\n{\nUNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation\n}\n,\nauthor\n=\n{\nKang, Wonjun and Ahn, Byeongkeun and Lee, Minjae and Galim, Kevin and Oh, Seunghyuk and Koo, Hyung Il and Cho, Nam Ik\n}\n,\njournal\n=\n{\narXiv preprint arXiv:2508.05399\n}\n,\nyear\n=\n{\n2025\n}\n}",
            "children": []
          }
        ]
      }
    ]
  },
  "metadata": {
    "description": "UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation",
    "license": null,
    "stars": 17,
    "forks": 0,
    "topics": [],
    "last_updated": "2025-11-14T00:38:54.308339Z"
  }
}