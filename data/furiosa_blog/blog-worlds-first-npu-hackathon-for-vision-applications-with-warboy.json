{
  "metadata": {
    "url": "https://furiosa.ai/blog/worlds-first-npu-hackathon-for-vision-applications-with-warboy",
    "title": "World's first NPU Hackathon for Vision Applications with Furiosa's Gen 1 Vision NPU",
    "category": "News",
    "date": "2024-04-30T13:22:00+02:00"
  },
  "content": "To build technology that solves real-world needs, you have to put your products in the hands of a wide range of talented people who can provide feedback and inspiration for future work.\n\nThis is crucial for FuriosaAI, because we’ve set ourselves the ambitious goal of making AI computing sustainable and accessible to everyone. To do this in a world with soaring demand for AI hardware, we are building chips that are not just highly performant, but also programmable, scalable, easy to deploy, and vastly more power efficient.\n\nLast fall, FuriosaAI held its first hackathon (co-hosted with Elice ) to assess the strength of our SDK and software stack for our Gen 1 Vision NPU, which accelerates inference for more than 100 computer vision models.\n\nA hackathon is a uniquely valuable way to get feedback on products like our Gen 1 Vision NPU. With no prior experience working with the chip or Furiosa’s SDK , participants had 24 hours to build and run a new computer vision application. After the event ended, we conducted a detailed survey of the engineers who took part in order to learn what went well, where their pain points were, and how we can make it easier to accomplish real-world tasks with our Gen 1 NPU.\n\nAs we gear up to launch our second-gen chip, RNGD, later this year, we’ve been able to leverage the insights we’ve gathered from hosting the hackathon and working with customers using our Gen 1 NPU in production applications.\n\nMore than 1,000 people submitted hackathon applications and 40 were selected as semifinalists. They gathered in a downtown Seoul conference room in late November to build their projects and compete for a series of prizes. In preparation, Elice installed 40 Gen 1 NPU cards on servers in their data center and Furiosa engineers (and company advisors like Nuno Lopes, a compiler expert and associate professor at Lisbon University of Science and Technology ) were on hand to answer questions and provide support.\n\nHackathon participants started with little or no familiarity with the Gen 1 NPU card or the FuriosaAI SDK, and then had to develop, build, and debug their project in just 24 hours. The teams included people with a very wide range of experience, including professional AI engineers, academic researchers with PhDs in Computer Science, and college students who have not yet worked professionally in the field.\n\nDespite the high-pressure environment, every team was able to get results from their project during the 24-hour event. Prize-winning projects ranged from accident detection on CCTV cameras to vocabulary-building tools for education.\n\nOne team used the card to analyze people’s facial expressions and generate personalized color recommendations for them. “We are building a service that extracts features from images of faces. Image detection, and recognition are all implemented by AI,” said the team leader, Gayeon Yu. “So the card's remarkable performance and a specialized architecture in computer vision are helping us greatly in this project.”\n\nThe grand prize was awarded to a team that created a service to protect people’s privacy by blurring their faces in video in real time. They deployed two different computer vision models running simultaneously on a single card: One model to detect the presence of people in the video, and one to blur the faces and bodies of people once they’ve been detected.\n\nWe were pleased to see that hackathon participants reported high satisfaction and low difficulty with the Furiosa SDK. We also found ways we can improve it – especially for students and other relatively inexperienced practitioners. These areas include additional resources on quantization and exporting to ONNX, as well as adding more documentation and low-level APIs.\n\nThis feedback has been top of mind as we prepare for the launch of RNGD (pronounced “Renegade”), which will be the most efficient data center accelerator for inference with high-performance LLMs and multimodal models.\n\nYou can learn more about our Gen 1 Vision NPU here . Sign up here to be notified first about RNGD availability and product updates."
}