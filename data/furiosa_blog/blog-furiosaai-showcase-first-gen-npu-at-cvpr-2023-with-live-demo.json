{
  "metadata": {
    "url": "https://furiosa.ai/blog/furiosaai-showcase-first-gen-npu-at-cvpr-2023-with-live-demo",
    "title": "FuriosaAI showcases Gen 1 NPU at CVPR 2023 with live demo",
    "category": "News",
    "date": "2023-06-27T00:00:00+02:00"
  },
  "content": "After making rapid progress on commercializing its first-gen Neural Processing Unit (NPU) for computer vision applications, FuriosaAI was excited to bring working cards and a live demo for the more than 10,000 attendees at this year’s CVPR conference in Vancouver.\n\nWe first showcased our first-gen NPU at CVPR 2022. It was a pleasure to return with a commercialized product and share it with computer vision researchers and practitioners, many of whom remembered stopping by our booth last year.\n\nOur chip is designed to efficiently accelerate computer vision tasks in both data centers and on-prem and edge deployments. Running YOLOv5s, it delivers peak performance of 330 FPS on a single card, which allows for object detection at 40 FPS on eight concurrent streams.\n\nAt CVPR 2023, we demonstrated running example applications, including object detection/multiple object tracking (yolov8), semantic segmentation (BiSeNetv1), instance segmentation (yolov8-seg), facial recognition (RetinaFace-MobileNet0.25), and pose estimation (yolov7-pose). We also showcased commercial deployment use cases across optical character recognition, super resolution, and object detection applications. Our MOT and OCR demos are available to try on Hugging Face.\n\nA commercial product, not just a proof of concept\n\nCommercializing our first-gen chip has been crucial to achieving Furiosa’s long-term vision for dramatically expanding access to powerful AI compute.\n\nBy shipping our first-gen chip, we’re learning how best to meet business’ real-world needs: which models are most important to support, how best to integrate our products into complex deployments, and how our products perform in a wide variety of commercial use cases.\n\nThis is especially important as we develop our second-gen chip, RNGD (pronounced \"Renegade\"), which is designed for inference with large language models and multimodal models. These algorithms are more resource-intensive than typical computer vision applications, so it’s essential that we build a hardware and software stack that delivers high performance, ease of use, and dramatically improved power efficiency. Our second-gen chip will launch in 2024.\n\nTrends at CVPR\n\nAt our CVPR 2023 booth, we heard feedback from people across the AI community and got first-hand insights into where the field of computer vision is heading next.\n\nThe experts we spoke with were excited to integrate large language models (LLMs) into their computer vision projects. We observed interesting new work to extend diffusion into denoising, image editing, and style transfer. NeRFs (Neural Radiance Fields, a method of generating high-quality 3D representations) have moved beyond proof of concept to editing, applications, and training process optimization.\n\nWe also heard concerns from both industry and academia about the rising cost of compute. Without hardware that offers a lower TCO (total cost of ownership, which includes the cost of electricity to power and cool the chips as well as the upfront price tag), many fear innovation will be stifled, leaving fewer people with access to new AI-powered services. Sign up here to be notified first about RNGD's availability and product updates. Y ou can also learn more about our first-gen product and schedule a demo here ."
}