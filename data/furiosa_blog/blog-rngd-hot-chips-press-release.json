{
  "metadata": {
    "url": "https://furiosa.ai/blog/rngd-hot-chips-press-release",
    "title": "Press Release: FuriosaAI Unveils RNGD, A Leading AI Inference Chip",
    "category": "News",
    "date": "2024-08-26T02:00:00+02:00"
  },
  "content": "SANTA CLARA, Calif., August 26, 2024 — FuriosaAI , an emerging leader in the AI semiconductor space, today announced the unveiling of RNGD (pronounced “Renegade”), a leading AI accelerator, at Hot Chips 2024. RNGD is positioned to be the most efficient data center accelerator for high-performance large language model (LLM) and multimodal model inference, disrupting an AI hardware landscape long defined by legacy chipmakers and high-profile startups. Founded in 2017 by three engineers with backgrounds at AMD, Qualcomm, and Samsung, the company has pursued a strategy focused on rapid innovation and product delivery, which has resulted in the unveiling and fast development of RNGD.\n\nFuriosa successfully completed the full bring-up of RNGD after receiving the first silicon samples from its partner, TSMC. This achievement reinforces the company's track record of fast and seamless technology development. With its first-generation chip, introduced in 2021, Furiosa submitted its first MLPerf benchmark results within three weeks of receiving silicon and achieved a 113% performance increase in its next submission through compiler enhancements.\n\nEarly testing of RNGD has revealed promising results with large language models such as GPT-J and Llama 3.1. A single RNGD PCIe card delivers 2,000 to 3,000 tokens per second throughput performance (depending on context length) for models with around 10 billion parameters.\n\n“The launch of RNGD is the result of years of innovation, leading to a one-shot silicon success and exceptionally rapid bring-up process. RNGD is a sustainable and accessible AI computing solution that meets the industry’s real-world needs for inference,” said June Paik, co-founder and CEO of FuriosaAI. “With our hardware now starting to run LLMs at high performance, we’re entering an exciting phase of continuous advancement. I am incredibly proud and grateful to the team for their hard work and continuous dedication.”\n\nJune will present performance benchmarks at Hot Chips today in a presentation titled, “Furiosa RNGD: A Tensor Contraction Processor for Sustainable AI Computing,” and which further underscores RNGD’s exceptional capabilities, leaving industry experts eagerly anticipating what comes next. He will offer a first hands-on look at the fully functioning RNGD card along with a live demo at Furiosa's booth.\n\nRNGD's key innovations include:\n\nA non-matmul, Tensor Contraction Processor (TCP) based architecture that enables a perfect balance of efficiency, programmability and performance\n\nA non-matmul, Tensor Contraction Processor (TCP) based architecture that enables a perfect balance of efficiency, programmability and performance\n\nProgrammability through a robust compiler co-designed to be optimized for TCP that treats entire models as single-fused operations\n\nProgrammability through a robust compiler co-designed to be optimized for TCP that treats entire models as single-fused operations\n\nEfficiency, with a TDP of 150W compared to 1,000W+ for leading GPU\n\nEfficiency, with a TDP of 150W compared to 1,000W+ for leading GPU\n\nHigh-performance, with 48GB of HBM3 memory, delivering the ability to run models like Llama 3.1 8B efficiently on a single card\n\nHigh-performance, with 48GB of HBM3 memory, delivering the ability to run models like Llama 3.1 8B efficiently on a single card\n\nWhat our industry partners have to say:\n\n“The Furiosa RNGD AI Inference solution drives the adoption of green computing with Supermicro. By integrating Furiosa's technology, Supermicro systems can reduce power consumption per card while still delivering exceptional inference performance,” said Vik Malyala, SVP, Technology and AI; President & Managing Director, EMEA, Supermicro.\n\n“The collaboration between GUC and FuriosaAI to deliver RNGD with exceptional performance and power efficiency hinges on meticulous planning and execution. Achieving this requires a deep understanding of modern AI software and hardware. FuriosaAI has consistently demonstrated excellence from design to delivery, creating the most efficient AI inference chips in the industry,” said Aditya Raina, CMO of GUC.\n\nThe chip is currently sampling to early access customers, with broader availability expected in early 2025.\n\nFor more details on RNGD's architecture and capabilities, please visit FuriosaAI’s blog .\n\nAbout FuriosaAI\n\nFuriosaAI is a semiconductor company dedicated to creating sustainable AI computing solutions that make powerful AI accessible to all. With its innovative Tensor Contraction Processor architecture, FuriosaAI is revolutionizing the AI hardware landscape, offering unparalleled efficiency and programmability for the most demanding AI workloads. For more information, please visit furiosa.ai .\n\nMedia Contact\n\nOliver Libaw: oliver@furiosa.ai"
}