{
  "title": "Structured Output",
  "url": "https://developer.furiosa.ai/latest/en/furiosa_llm/structured-output.html",
  "version": "2025.3.1",
  "content": "# Structured Output[#](#structured-output \"Link to this heading\")\n\nFuriosa-LLM supports structured output generation, enabling you to constrain\nthe model’s output to follow specific formats, schemas, or patterns.\nThis feature is essential for applications requiring consistent,\nparsable responses such as JSON data extraction and any-formatted text generation.\n\nNote\n\nFuriosa-LLM uses [llguidance](https://github.com/guidance-ai/llguidance)\nas the default backend for guided decoding. This backend ensures efficient constraint\nenforcement during the token generation process. Additional backends\nlike [XGrammar](https://github.com/mlc-ai/xgrammar) will be supported soon,\nproviding even more grammar format options and enhanced performance.\n\n## Supported Methods via OpenAI API[#](#supported-methods-via-openai-api \"Link to this heading\")\n\nUsers can generate structured outputs using both OpenAI’s [Completions API](https://platform.openai.com/docs/api-reference/completions) and\n[Chat Completions API](https://platform.openai.com/docs/api-reference/chat).\nFuriosa-LLM supports four main types of structured output constraints:\n\n* Choices: Forces the output to be one of predefined options\n* Regular Expressions: Generates text matching a specific regular expression pattern\n* JSON Schema: Produces JSON output following a predefined schema\n* Context-free Grammar: Generates text following a context-free grammar specification\n\n### Choices[#](#choices \"Link to this heading\")\n\nThe `guided_choice` parameter constrains the model output to be one of a predefined set of choices. This is particularly useful for classification tasks or when you need the model to select from specific options.\n\n**Usage Example:**\n\n```\nfrom openai import OpenAI\n\nbase_url = \"http://localhost:8000/v1\" # Replace this with your base URL\napi_key = \"EMPTY\"\nclient = OpenAI(api_key=api_key, base_url=base_url)\n\n# Sample review to classify\nreview = \"This movie was absolutely fantastic!\"\n\nresponse = client.chat.completions.create(\n    model=client.models.list().data[0].id,\n    messages=[{\"role\": \"user\", \"content\": f\"Classify sentiment: '{review}'\"}],\n    extra_body={\"guided_choice\": [\"positive\", \"negative\", \"neutral\"]},\n    temperature=0.0,\n)\n\nprint(response.choices[0].message.content)\n```\n\nCopy to clipboard\n\n**Use Cases:**\n\n* Sentiment analysis\n* Category classification\n* Multiple choice questions\n* Binary decisions (yes/no, true/false)\n\n### Regular Expressions[#](#regular-expressions \"Link to this heading\")\n\nThe `guided_regex` parameter ensures the generated text matches a specific regular expression pattern. This is useful for generating structured text like email addresses, phone numbers, or custom formats.\n\n**Usage Example:**\n\n```\nfrom openai import OpenAI\n\nbase_url = \"http://localhost:8000/v1\" # Replace this with your base URL\napi_key = \"EMPTY\"\nclient = OpenAI(api_key=api_key, base_url=base_url)\n\n# Email address pattern\nemail_pattern = r\"[a-z0-9.]{1,20}@\\w{6,10}\\.com\\n\"\n\nresponse = client.chat.completions.create(\n    model=client.models.list().data[0].id,\n    messages=[{\"role\": \"user\", \"content\": \"Generate an email address for Ada Lovelace, who works in Analytical. End in .com and new line. Example result: 'ada.lovelace@analytical.com\\n'\"}],\n    extra_body={\"guided_regex\": email_pattern},\n    temperature=0.0,\n)\n\nprint(response.choices[0].message.content)\n```\n\nCopy to clipboard\n\n**Use Cases:**\n\n* Email address generation\n* Phone number formatting\n* ID or code generation\n* Custom text patterns\n* URL or file path generation\n\n### JSON Schema[#](#json-schema \"Link to this heading\")\n\nThe `guided_json` parameter is the most commonly used structured output method. It ensures the generated output is valid JSON that conforms to a specified schema. This is ideal for extracting structured data or creating consistent API responses.\n\n**Usage Example:**\n\n```\n#!/usr/bin/env python3\n\"\"\"\nExample: Guided JSON - Data Extraction\n\"\"\"\n\nimport enum\nimport json\nfrom openai import OpenAI\nimport pydantic\n\nbase_url = \"http://localhost:8000/v1\" # Replace this with your base URL\napi_key = \"EMPTY\"\nclient = OpenAI(api_key=api_key, base_url=base_url)\n\nclass Color(str, enum.Enum):\n    BLUE = \"blue\"\n    GREEN = \"green\"\n    PURPLE = \"purple\"\n\nclass FruitDescription(pydantic.BaseModel):\n    name: str\n    color: Color\n    taste: str\n\nresponse = client.chat.completions.create(\n    model=client.models.list().data[0].id,\n    messages=[{\"role\": \"user\", \"content\": \"Generate a JSON with the name, color, and taste of your favorite fruit.\"}],\n    response_format={\n        \"type\": \"json_schema\",\n        \"json_schema\": {\n            \"name\": \"fruit-description\",\n            \"schema\": FruitDescription.model_json_schema(),\n        },\n    },\n    temperature=0.0,\n)\n\nresult = json.loads(response.choices[0].message.content)\nprint(json.dumps(result, indent=2))\n```\n\nCopy to clipboard\n\n**Use Cases:**\n\n* Data extraction from unstructured text\n* API response formatting\n* Database record creation\n* Configuration file generation\n\n### Context-free Grammar[#](#context-free-grammar \"Link to this heading\")\n\nThe `guided_grammar` parameter allows you to define a context-free grammar specification that the generated text must follow. This provides the most flexible control over output structure.\n\n**Grammar Format Support:**\n\nThe llguidance backend currently supports multiple grammar formats:\n\n* **EBNF (Extended Backus-Naur Form)**: Standard grammar notation with `::=` syntax\n* **Lark**: a modern parsing library for Python ([Lark document](https://lark-parser.readthedocs.io/en/stable/))\n\n**Usage Example:**\n\n```\nfrom openai import OpenAI\n\nbase_url = \"http://localhost:8000/v1\" # Replace this with your base URL\napi_key = \"EMPTY\"\nclient = OpenAI(api_key=api_key, base_url=base_url)\n\n\n# Grammar for SQL SELECT statements\nsql_grammar = \"\"\"\nroot ::= select_statement\n\nselect_statement ::= \"SELECT \" column \" FROM \" table \" WHERE \" condition\n\ncolumn ::= \"username\" | \"email\"\n\ntable ::= \"users\"\n\ncondition ::= \"id = \" number\n\nnumber ::= \"1\" | \"2\" | \"3\"\n\"\"\"\n\nresponse = client.chat.completions.create(\n    model=client.models.list().data[0].id,\n    messages=[{\"role\": \"user\", \"content\": \"Generate an SQL query to show the 'username' from the 'users' table.\"}],\n    extra_body={\"guided_grammar\": sql_grammar},\n    temperature=0.0,\n    max_tokens=100\n)\n\nprint(response.choices[0].message.content)\n```\n\nCopy to clipboard\n\nThe example above uses EBNF format with the `::=` notation. You can also use Lark format with different syntax rules depending on your grammar complexity requirements.\n\n**Use Cases:**\n\n* SQL query generation\n* Code generation with specific syntax\n* Mathematical expressions\n* Custom domain-specific languages\n* Complex structured formats",
  "external_links": [
    {
      "text": "llguidance",
      "url": "https://github.com/guidance-ai/llguidance"
    },
    {
      "text": "XGrammar",
      "url": "https://github.com/mlc-ai/xgrammar"
    },
    {
      "text": "Completions API",
      "url": "https://platform.openai.com/docs/api-reference/completions"
    },
    {
      "text": "Chat Completions API",
      "url": "https://platform.openai.com/docs/api-reference/chat"
    },
    {
      "text": "Lark document",
      "url": "https://lark-parser.readthedocs.io/en/stable/"
    }
  ]
}