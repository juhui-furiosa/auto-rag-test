{
  "title": "FuriosaAI RNGD",
  "url": "https://developer.furiosa.ai/latest/en/overview/rngd.html#",
  "version": "2025.3.1",
  "content": "# FuriosaAI RNGD[#](#furiosaai-rngd \"Link to this heading\")\n\nFuriosaAI’s second-generation Neural Processing Unit (NPU), RNGD, is a chip designed for deep learning inference,\nsupporting high-performance Large Language Models (LLM), Multi-Modal LLM, Vision models,\nand other deep learning models.\n\n[![FuriosaAI RNGD](../_images/Furiosa_RNGD_image.png)](../_images/Furiosa_RNGD_image.png)\n\nRNGD is based the Tensor Contraction Processor (TCP) architecture which\nutilizes TSMC’s 5nm process node, and operates at 1.0 GHz. It offers 512 TOPS and 1024 TOPS of INT8 and INT4\nperformance, respectively.\nRNGD is configured with two HBM3 modules providing a memory bandwidth of 1.5 TB/s,\nand supports PCIe Gen5 x16. For multi-tenant environments like Kubernetes,\na single RNGD chip can work as 2, 4, or 8 individual NPUs, each fully isolated with its own cores and memory bandwidth.\nRNGD supports Single Root IO Virtualization (SR-IOV) and virtualization for multi-instance NPUs.\n\nPlease refer to the followings to learn more about TCP architecture and RNGD:\n\n* [TCP: A Tensor Contraction Processor for AI Workloads, ACM/IEEE ISCA 2024](https://ieeexplore.ieee.org/document/10609575) ([PDF](https://furiosa.ai/download/FuriosaAI-tensor-contraction-processor-isca24))\n* [FuriosaAI RNGD: A Tensor Contraction Processor for Sustainable AI Computing, Hotchips 2024](https://hc2024.hotchips.org/#clip=8jnhm5vdlsow)\n* [Tensor Contraction Processor: The first future-proof AI chip architecture](https://furiosa.ai/blog/tensor-contraction-processor-ai-chip-architecture)\n\nRNGD Hardware Specification[#](#id1 \"Link to this table\")\n\n\n\n\n|  |  |\n| --- | --- |\n| Architecture | Tensor Contraction Processor |\n| Process Node | TSMC 5nm |\n| Frequency | 1.0 GHz |\n| BF16 | 256 TFLOPS |\n| FP8 | 512 TFLOPS |\n| INT8 | 512 TOPS |\n| INT4 | 1024 TOPS |\n| Memory Bandwidth | HBM3 1.5TB/s |\n| Memory Capacity | HBM3 48GB |\n| On-Chip SRAM | 256MB |\n| Interconnect Interface | PCIe Gen5 x16 |\n| Thermal Solution | Passive |\n| Thermal Design Power (TDP) | 150W |\n| Power Connector | 12VHPWR |\n| Form Factor | PCIe dual-slot full-height 3/4 Length |\n| Multi-Instance Support | 8 |\n| Virtualization Support | Yes |\n| SR-IOV | 8 Virtual Functions |\n| ECC Memory Support | Yes |\n| Secure Boot with Root of Trust | Yes |",
  "external_links": [
    {
      "text": "TCP: A Tensor Contraction Processor for AI Workloads, ACM/IEEE ISCA 2024",
      "url": "https://ieeexplore.ieee.org/document/10609575"
    },
    {
      "text": "PDF",
      "url": "https://furiosa.ai/download/FuriosaAI-tensor-contraction-processor-isca24"
    },
    {
      "text": "FuriosaAI RNGD: A Tensor Contraction Processor for Sustainable AI Computing, Hotchips 2024",
      "url": "https://hc2024.hotchips.org/#clip=8jnhm5vdlsow"
    },
    {
      "text": "Tensor Contraction Processor: The first future-proof AI chip architecture",
      "url": "https://furiosa.ai/blog/tensor-contraction-processor-ai-chip-architecture"
    }
  ]
}