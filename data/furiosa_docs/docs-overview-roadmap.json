{
  "title": "Roadmap",
  "url": "https://developer.furiosa.ai/latest/en/overview/roadmap.html",
  "version": "2025.3.1",
  "content": "# Roadmap[#](#roadmap \"Link to this heading\")\n\nFuriosaAI is committed to delivering the releases for each month, while offering patch releases.\nThis page shows the forward-looking roadmap of ongoing & upcoming projects and when they are expected to land, broken down by areas on\n[our software stack](software_stack.html#softwarestack).\n\nNote\n\nThe latest release is 2025.3.1. You can find the release notes [here](../whatsnew/index.html#whatsnew).\n\n## Upcoming Releases 2025 Q4[#](#upcoming-releases-2025-q4 \"Link to this heading\")\n\n* ğŸ”¨ Hybrid batching support\n* ğŸ”¨ Qwen3 MoE model support in Furiosa-LLM\n* ğŸ”¨ Speculating with a draft model\n* ğŸ”¨ CPU memory swapping of KV cache in Furiosa-LLM\n* ğŸ”¨ `torch.compile()` backend\n* ğŸ”¨ llm-d integration\n\n## Upcoming Releases 2025 Q3[#](#upcoming-releases-2025-q3 \"Link to this heading\")\n\n* ğŸ”¨ Qwen3 support in Furiosa-LLM\n* âœ… Guided-decoding support in Furiosa-LLM\n* ğŸ”¨ Prefix-caching support in Furiosa-LLM\n* ğŸ”¨ Pooling Model support in Furiosa-LLM\n* ğŸ”¨ NPU operator support for Kubernetes\n* âœ… Fine-tuned model support in Furiosa-LLM\n* âœ… Tensor Parallelism support Phase 2: Inter-chip\n* âœ… Dramatic performance improvements in Furiosa-LLM (7x higher throughput than 2025.1.0 release)\n* âœ… Hugging Face Hub support in Furiosa-LLM\n* âœ… Pre-compiled artifacts on Hugging Face Hub\n* âœ… Qwen2 and Qwen2.5 model support in Furiosa-LLM\n* âœ… EXAONE3 model support in Furiosa-LLM\n\n## 2025 Q1 - 2025 Q2[#](#q1-2025-q2 \"Link to this heading\")\n\n* âœ… Tool-calling support in Furiosa-LLM (2025.1.0 release)\n* âœ… Device remapping support (e.g., /dev/rngd/npu2pe0-3 -> /dev/rngd/npu0pe0-3) for container (2025.1.0 release)\n* âœ… Automatic configuration for the maximum KV-cache memory allocation (2025.1.0 release)\n* âœ… Min-p sampling support (2025.1.0 release)\n* âœ… Chunked Prefill support in Furiosa-LLM (planned for 2025.2.0 release)\n* âœ… Chat API support in Furiosa-LLM (planned for 2025.2.0 release)\n* âœ… Reasoning parser support (2025.2.0 release)\n* âœ… Torch 2.5.1 support (2025.2.0 release)\n* âœ… Python 3.11 and 3.12 support (2025.2.0 release)\n* âœ… Support for building bfloat16, float16, and float32 models to model artifact without quantization (2025.2.0 release)\n* âœ… Metrics endpoint (`/metrics/`) support in Furiosa-LLM (2025.2.0 release)\n* âœ… Model artifact support in Huggingface Hub (2025.2.0 release)\n* âœ… Sampling parameter â€œlogprobsâ€ support (2025.2.0 release)\n* âœ… Container Runtime and Container Interface Device (CDI) support (2025.2.0 release)\n\n## 2024 Q4[#](#q4 \"Link to this heading\")\n\n* âœ… Language Model Support: CodeLLaMA2, Vicuna, Solar, EXAONE-3.0 (2024.2.0 release)\n* âœ… Vision Model Support: MobileNetV1, MobileNetV2, ResNet152, ResNet50, EfficientNet, YOLOv8m, etc (2024.2.0 release)\n* âœ… Tensor Parallelism support Phase 1: Intra-chip (2024.2.0 release)\n* âœ… Torch 2.4.1 support (2024.2.0)\n* âœ… Huggingface Optimum integration (2024.2.0 release)",
  "external_links": []
}